{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d678ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 14:13:05.000848: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8aecbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'datasets/Images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94c488ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 160\n",
    "img_width = 160\n",
    "\n",
    "img_shape = (160,160,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5762250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20580 files belonging to 120 classes.\n",
      "Using 16464 files for training.\n",
      "Found 20580 files belonging to 120 classes.\n",
      "Using 4116 files for validation.\n"
     ]
    }
   ],
   "source": [
    "#_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "#path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
    "#PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
    "#data_dir = os.path.join(PATH, 'train')\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(data_dir,\n",
    "                                                            shuffle=True,\n",
    "                                                            subset='training',\n",
    "                                                            seed = 123,\n",
    "                                                            validation_split=0.2,\n",
    "                                                            batch_size=batch_size,\n",
    "                                                            image_size=(img_height, img_width),\n",
    "                                                            label_mode='categorical')\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(data_dir,\n",
    "                                                                 shuffle=True,\n",
    "                                                                 subset='validation',\n",
    "                                                                 seed = 123,\n",
    "                                                                 validation_split=0.2,\n",
    "                                                                 batch_size=batch_size,\n",
    "                                                                 image_size=(img_height, img_width),\n",
    "                                                                 label_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "48fb222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "\n",
    "#plt.figure(figsize=(10, 10))\n",
    "#for images, labels in train_dataset.take(1):\n",
    "#    for i in range(9):\n",
    "#        ax = plt.subplot(3, 3, i + 1)\n",
    "#        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#        plt.title(class_names[labels[i]])\n",
    "#        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07792ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c49da16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.RandomRotation(0.15),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5bae1f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8836210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = tf.keras.layers.Rescaling(1./127.5, offset=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae9465a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=img_shape,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a539c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4f117928",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(120, \n",
    "                                         activation = 'softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f919cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "804ce2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d06bc45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ec053f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 101s 764ms/step - loss: 5.2234 - accuracy: 0.0073\n"
     ]
    }
   ],
   "source": [
    "initial_epochs = 5\n",
    "\n",
    "loss0, accuracy0 = model.evaluate(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d97af31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "515/515 [==============================] - 486s 928ms/step - loss: 4.0056 - accuracy: 0.1374 - val_loss: 2.6847 - val_accuracy: 0.4278\n",
      "Epoch 2/5\n",
      "515/515 [==============================] - 513s 997ms/step - loss: 2.5268 - accuracy: 0.4018 - val_loss: 1.7495 - val_accuracy: 0.6312\n",
      "Epoch 3/5\n",
      "515/515 [==============================] - 529s 1s/step - loss: 1.9440 - accuracy: 0.5172 - val_loss: 1.3397 - val_accuracy: 0.6922\n",
      "Epoch 4/5\n",
      "515/515 [==============================] - 499s 969ms/step - loss: 1.6559 - accuracy: 0.5741 - val_loss: 1.1332 - val_accuracy: 0.7247\n",
      "Epoch 5/5\n",
      "515/515 [==============================] - 525s 1s/step - loss: 1.4937 - accuracy: 0.6045 - val_loss: 1.0093 - val_accuracy: 0.7408\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=validation_dataset,\n",
    "                    batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619eb4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
